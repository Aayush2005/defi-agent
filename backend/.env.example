# DeFi AI Assistant Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# API KEYS (Required)
# =============================================================================

# OpenAI API Key for GPT-4o-mini
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Pinecone API Key for vector database
# Get from: https://app.pinecone.io/
PINECONE_API_KEY=your-pinecone-api-key-here

# LangSmith API Key for observability
# Get from: https://smith.langchain.com/
LANGSMITH_API_KEY=your-langsmith-api-key-here

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Pinecone Index Name
PINECONE_INDEX=defi-queries

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your-redis-password-here

# =============================================================================
# SECURITY & CORS SETTINGS
# =============================================================================

# Debug mode (set to false in production)
DEBUG=false

# Allowed origins for CORS (comma-separated)
# Add your frontend URLs here
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:8501","http://localhost:8080"]

# =============================================================================
# RATE LIMITING
# =============================================================================

# Requests per minute per IP
RATE_LIMIT_PER_MINUTE=60

# Requests per hour per IP
RATE_LIMIT_PER_HOUR=1000

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Default OpenAI model
DEFAULT_MODEL=gpt-4o-mini

# Model temperature (0.0 for deterministic, 1.0 for creative)
DEFAULT_TEMPERATURE=0.0

# Maximum tokens in response
MAX_TOKENS=1000

# =============================================================================
# VECTOR SEARCH SETTINGS
# =============================================================================

# Number of top results to retrieve
VECTOR_SEARCH_TOP_K=3

# Confidence thresholds for routing logic
HIGH_CONFIDENCE_THRESHOLD=0.98
MEDIUM_CONFIDENCE_THRESHOLD=0.90

# =============================================================================
# SESSION MANAGEMENT
# =============================================================================

# Session TTL in seconds (300 = 5 minutes)
SESSION_TTL=300

# Maximum conversation history to keep
MAX_CONVERSATION_HISTORY=10

# =============================================================================
# LANGCHAIN TRACING
# =============================================================================

# Enable LangChain tracing
LANGCHAIN_TRACING_V2=true

# LangChain project name
LANGCHAIN_PROJECT=DeFi AI Assistant