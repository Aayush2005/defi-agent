# DeFi AI Assistant Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# API KEYS (Required)
# =============================================================================

# =============================================================================
# MODEL SYSTEM SELECTION
# =============================================================================

# Choose your AI system: true = Free Gemini, false = Paid GPT-5
USE_GEMINI=true

# OpenAI API Key (only needed if USE_GEMINI=false)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Google API Key (only needed if USE_GEMINI=true)
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# Pinecone API Key for vector database
# Get from: https://app.pinecone.io/
PINECONE_API_KEY=your-pinecone-api-key-here

# LangSmith API Key for observability
# Get from: https://smith.langchain.com/
LANGSMITH_API_KEY=your-langsmith-api-key-here

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Pinecone Index Name
PINECONE_INDEX=defi-queries

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your-redis-password-here

# =============================================================================
# SECURITY & CORS SETTINGS
# =============================================================================

# Debug mode (set to false in production)
DEBUG=false

# Allowed origins for CORS (comma-separated)
# Add your frontend URLs here
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:8501","http://localhost:8080"]

# =============================================================================
# RATE LIMITING
# =============================================================================

# Requests per minute per IP
RATE_LIMIT_PER_MINUTE=60

# Requests per hour per IP
RATE_LIMIT_PER_HOUR=1000

# =============================================================================
# MODEL CONFIGURATION (GPT-5 Ready!)
# =============================================================================

# Default OpenAI model
DEFAULT_MODEL=gpt-5-mini
FALLBACK_MODEL=gpt-4o-mini

# Model temperature (0.0 for deterministic, 1.0 for creative)
DEFAULT_TEMPERATURE=0.0

# Maximum tokens in response
MAX_TOKENS=1000

# Task-specific models (optimized for cost and performance)
INTENT_MODEL=gpt-5-nano        # Ultra-cheap for intent classification ($0.05 input)
QUERY_MODEL=gpt-5-mini         # Good balance for queries ($0.25 input)
ACTION_MODEL=gpt-5-mini        # Good for parameter extraction ($0.25 input)
ADVANCED_MODEL=gpt-5           # For complex reasoning ($1.25 input)

# =============================================================================
# VECTOR SEARCH SETTINGS
# =============================================================================

# Number of top results to retrieve
VECTOR_SEARCH_TOP_K=3

# Confidence thresholds for routing logic
HIGH_CONFIDENCE_THRESHOLD=0.98
MEDIUM_CONFIDENCE_THRESHOLD=0.90

# =============================================================================
# SESSION MANAGEMENT
# =============================================================================

# Session TTL in seconds (300 = 5 minutes)
SESSION_TTL=300

# Maximum conversation history to keep
MAX_CONVERSATION_HISTORY=10

# =============================================================================
# LANGCHAIN TRACING
# =============================================================================

# Enable LangChain tracing
LANGCHAIN_TRACING_V2=true

# LangChain project name
LANGCHAIN_PROJECT=DeFi AI Assistant